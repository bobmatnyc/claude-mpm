name: Documentation

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'docs/**'
      - 'src/**'
      - '.readthedocs.yaml'
      - 'pyproject.toml'
      - 'setup.py'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/**'
      - 'src/**'
      - '.readthedocs.yaml'
      - 'pyproject.toml'
      - 'setup.py'
  workflow_dispatch:

jobs:
  build-docs:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8', '3.11']

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for version detection

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y graphviz libgraphviz-dev pkg-config

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[docs]"
        pip install -r docs/api/requirements.txt

    - name: Build documentation
      run: |
        cd docs/api
        make clean
        make html
      env:
        READTHEDOCS: "True"
        CLAUDE_MPM_DOCS_BUILD: "True"

    - name: Check for build warnings
      run: |
        if grep -q "WARNING" docs/api/_build/html/output.txt 2>/dev/null; then
          echo "Documentation build produced warnings"
          grep "WARNING" docs/api/_build/html/output.txt
          exit 1
        fi
      continue-on-error: true

    - name: Type checking with mypy
      run: |
        echo "Running mypy type checking..."
        pip install mypy types-PyYAML types-requests

        # Run mypy on core modules first (strictest checking)
        echo "Checking core modules..."
        mypy src/claude_mpm/core/ --config-file mypy.ini || echo "Core modules have type issues (expected initially)"

        # Run mypy on the entire codebase with lenient settings
        echo "Checking entire codebase..."
        mypy src/claude_mpm/ --config-file mypy.ini || echo "Type checking completed with issues (expected initially)"

        echo "Type checking completed. See mypy.ini for configuration details."
      continue-on-error: true

    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v4
      with:
        name: documentation-${{ matrix.python-version }}
        path: docs/api/_build/html/
        retention-days: 7

    - name: Test documentation links
      run: |
        pip install sphinx-lint linkchecker requests beautifulsoup4

        # Check for broken internal links with Sphinx
        echo "Running Sphinx linkcheck..."
        python -m sphinx.cmd.build -b linkcheck docs/api docs/api/_build/linkcheck || echo "Sphinx linkcheck completed with issues"

        # Enhanced link validation script
        cat > validate_links.py << 'EOF'
        import os
        import re
        import requests
        from pathlib import Path
        from urllib.parse import urljoin, urlparse
        import time

        def extract_links_from_markdown(file_path):
            """Extract all links from a markdown file."""
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Find markdown links [text](url) and reference links [text]: url
            markdown_links = re.findall(r'\[([^\]]*)\]\(([^)]+)\)', content)
            reference_links = re.findall(r'^\[([^\]]+)\]:\s*(.+)$', content, re.MULTILINE)

            links = []
            for text, url in markdown_links + reference_links:
                if url.startswith(('http://', 'https://')):
                    links.append((text, url, file_path))
            return links

        def check_link(url, timeout=10):
            """Check if a URL is accessible."""
            try:
                response = requests.head(url, timeout=timeout, allow_redirects=True)
                return response.status_code < 400
            except:
                try:
                    # Try GET if HEAD fails
                    response = requests.get(url, timeout=timeout, allow_redirects=True)
                    return response.status_code < 400
                except:
                    return False

        def main():
            docs_dir = Path('docs')
            readme_files = [Path('README.md')]

            all_links = []

            # Collect links from documentation
            if docs_dir.exists():
                for md_file in docs_dir.rglob('*.md'):
                    all_links.extend(extract_links_from_markdown(md_file))

            # Collect links from README
            for readme in readme_files:
                if readme.exists():
                    all_links.extend(extract_links_from_markdown(readme))

            print(f"Found {len(all_links)} external links to validate")

            broken_links = []
            for i, (text, url, file_path) in enumerate(all_links):
                print(f"Checking {i+1}/{len(all_links)}: {url}")
                if not check_link(url):
                    broken_links.append((text, url, file_path))
                    print(f"  ✗ BROKEN: {url}")
                else:
                    print(f"  ✓ OK: {url}")

                # Rate limiting
                time.sleep(0.5)

            if broken_links:
                print(f"\n❌ Found {len(broken_links)} broken links:")
                for text, url, file_path in broken_links:
                    print(f"  - {url} in {file_path}")
                return 1
            else:
                print(f"\n✅ All {len(all_links)} links are working!")
                return 0

        if __name__ == '__main__':
            exit(main())
        EOF

        echo "Running enhanced link validation..."
        python validate_links.py || echo "Link validation completed with issues"

        # Check for common documentation issues
        echo "Checking for common documentation issues..."
        find docs -name "*.md" -exec grep -l "TODO\|FIXME\|XXX" {} \; | while read file; do
          echo "⚠️  Found TODO/FIXME in: $file"
          grep -n "TODO\|FIXME\|XXX" "$file" || true
        done

        # Check for broken internal references
        echo "Checking for broken internal references..."
        find docs -name "*.md" -exec grep -l "\[.*\](.*\.md)" {} \; | while read file; do
          echo "Checking internal links in: $file"
          grep -o "\[.*\]([^)]*\.md[^)]*)" "$file" | while read link; do
            ref_file=$(echo "$link" | sed 's/.*(\([^)]*\)).*/\1/' | sed 's/#.*//')
            if [ ! -f "docs/$ref_file" ] && [ ! -f "$ref_file" ]; then
              echo "  ✗ Broken internal link: $link in $file"
            fi
          done
        done
      continue-on-error: true

  validate-readthedocs-config:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'

    - name: Install validation tools
      run: |
        pip install pyyaml jsonschema

    - name: Validate .readthedocs.yaml
      run: |
        python -c "
        import yaml
        import sys

        with open('.readthedocs.yaml', 'r') as f:
            config = yaml.safe_load(f)

        # Basic validation
        assert config.get('version') == 2, 'Config version must be 2'
        assert 'sphinx' in config, 'Sphinx configuration required'
        assert 'python' in config, 'Python configuration required'
        assert 'build' in config, 'Build configuration required'

        print('✓ .readthedocs.yaml is valid')
        "

    - name: Check documentation structure
      run: |
        # Ensure required files exist
        test -f docs/api/conf.py || exit 1
        test -f docs/api/index.rst || exit 1
        test -f docs/api/requirements.txt || exit 1
        test -d docs/api/_static || mkdir -p docs/api/_static
        test -f docs/api/_static/custom.css || touch docs/api/_static/custom.css
        echo "✓ Documentation structure is valid"

  test-sphinx-build:
    runs-on: ubuntu-latest
    needs: [build-docs]

    steps:
    - uses: actions/checkout@v4

    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: documentation-3.11
        path: docs/api/_build/html/

    - name: Check generated files
      run: |
        # Verify essential files were generated
        test -f docs/api/_build/html/index.html || exit 1
        test -f docs/api/_build/html/search.html || exit 1
        test -f docs/api/_build/html/genindex.html || exit 1
        test -f docs/api/_build/html/py-modindex.html || exit 1
        echo "✓ Essential documentation files generated successfully"

    - name: Check documentation size
      run: |
        # Warn if documentation is unusually small (might indicate build issues)
        SIZE=$(du -sb docs/api/_build/html/ | cut -f1)
        if [ $SIZE -lt 1000000 ]; then
          echo "⚠ Warning: Documentation seems unusually small (< 1MB)"
        else
          echo "✓ Documentation size is reasonable"
        fi

  deploy-preview:
    runs-on: ubuntu-latest
    needs: [test-sphinx-build]
    if: github.event_name == 'pull_request'

    steps:
    - uses: actions/checkout@v4

    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: documentation-3.11
        path: docs/api/_build/html/

    - name: Deploy preview to Netlify
      uses: nwtgck/actions-netlify@v3.0
      with:
        publish-dir: './docs/api/_build/html'
        production-deploy: false
        github-token: ${{ secrets.GITHUB_TOKEN }}
        deploy-message: "Deploy from GitHub Actions"
        enable-pull-request-comment: true
        enable-commit-comment: false
        overwrites-pull-request-comment: true
      env:
        NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
        NETLIFY_SITE_ID: ${{ secrets.NETLIFY_SITE_ID }}
      continue-on-error: true
